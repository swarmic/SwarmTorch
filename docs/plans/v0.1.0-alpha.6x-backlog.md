# v0.1.0-alpha.6.x Backlog: DataOps Artifact Contract Hardening

Status: Draft for execution  
Scope: Dataset registry and materialization emitter path (`swarm-torch-core/src/dataops.rs`, `swarm-torch/src/artifacts.rs`, `swarm-torch/src/report.rs`)  
Out of scope: UI commitments, scheduler commitments

## Context

Phases 1-2 are complete:
- Phase 1: canonical fingerprint placeholder helpers and emitter alignment
- Phase 2: end-to-end integration example (`swarm-torch/examples/artifact_pipeline.rs`)

This backlog addresses known emitter correctness, lineage integrity, cache auditability, durability/throughput, and security gaps while keeping the architecture artifact-first and UI/scheduler-agnostic.

## Prioritized Findings

### High severity

1. Missing inputs are silently ignored during fingerprinting/trust propagation (`swarm-torch/src/artifacts.rs` around `materialize_node_outputs` input scan and recipe computation).
2. Lineage can be corrupted for in-place transforms (`input.asset_key == output.asset_key`) due to output mutation before lineage input capture.
3. Emitter does not enforce `graph.json` output contract (`materialize_node_outputs` accepts arbitrary output list).

### Medium severity

4. Cache semantics are not auditable (`cache_hit` is caller supplied with no cache key/decision evidence).
5. Emitter scales poorly for long runs (full `registry.json` + `lineage.json` rewrite on each update).
6. Manifest consistency gap blocks mid-run artifact consumption (manifest finalized only at end by default).
7. Materialization records are too thin for DS debugging (no explicit input provenance, operation, status channel, or sequence).
8. Source descriptors can leak secrets unless callers self-police.
9. ADR-0017 currently includes normative fields not yet present in `NodeV1` (`op_hash/resources/cache_policy/materialization_policy`) and needs implementation-status clarity.

## Alpha.6.x Slices

| ID | Slice | Files | Definition of done |
|---|---|---|---|
| A6X-01 | Emitter correctness invariants (blocker) | `swarm-torch/src/artifacts.rs` | `materialize_node_outputs()` fails closed on missing/invalid inputs, snapshots inputs before output mutation, enforces output contract vs `node.outputs`, rejects duplicate output asset keys. |
| A6X-02 | Materialization schema v2 + cache evidence | `swarm-torch-core/src/dataops.rs`, `swarm-torch/src/artifacts.rs`, `swarm-torch/src/report.rs` | Add `MaterializationRecordV2`; emit input provenance + cache evidence; derive `cache_hit` from decision; report loads v1 and v2. |
| A6X-03 | Throughput + durability profiles | `swarm-torch/src/artifacts.rs`, `swarm-torch/src/report.rs` | Add strict/streaming artifact modes; append-only `registry_updates.ndjson` + `lineage_edges.ndjson`; compaction to snapshots on finalize/interval; configurable manifest refresh policy. |
| A6X-04 | Descriptor security + unsafe reason taxonomy | `swarm-torch-core/src/dataops.rs`, `swarm-torch/src/artifacts.rs` | URI redaction + descriptor size bounds; emit explicit `unsafe_reasons[]`; maintain zero raw-row default. |
| A6X-05 | ADR/WP/roadmap conformance lock | `ADRs.md`, `SWARM_TORCH_TECHNICAL_WHITE_PAPER_v0.1.md`, `ROADMAP.md` | ADR-0016/0017/0018 amended with new invariants and status qualifiers; acceptance criteria and conformance hooks mapped to tests/commands. |

## Exact Test Names

### A6X-01 tests

Recommended file: `swarm-torch/src/artifacts.rs` tests (or `swarm-torch/tests/dataops_contract.rs`)

- `materialize_fails_on_missing_input_asset`
- `materialize_fails_on_invalid_input_fingerprint_hex`
- `materialize_rejects_duplicate_output_asset_keys`
- `materialize_rejects_output_not_declared_in_node`
- `materialize_rejects_missing_declared_node_output`
- `lineage_uses_pre_mutation_input_fingerprint_for_in_place_transform`

### A6X-02 tests

- `materialization_v2_serialization_roundtrip` (`swarm-torch-core/src/dataops.rs`)
- `materialization_v2_includes_input_provenance` (`swarm-torch/src/artifacts.rs`)
- `cache_hit_is_derived_from_cache_decision` (`swarm-torch/src/artifacts.rs`)
- `cache_key_v0_stable_for_same_inputs` (`swarm-torch/src/artifacts.rs`)
- `cache_key_v0_changes_when_input_fingerprint_changes` (`swarm-torch/src/artifacts.rs`)
- `report_loads_materialization_v1_and_v2` (`swarm-torch/src/report.rs`)

### A6X-03 tests

- `registry_updates_log_replays_to_snapshot_equivalence`
- `lineage_updates_log_replays_to_snapshot_equivalence`
- `streaming_profile_defers_snapshot_rewrite_until_interval`
- `strict_profile_updates_manifest_on_each_write`
- `manifest_interval_policy_refreshes_after_n_writes`
- `mid_run_report_succeeds_with_manifest_always_policy`

### A6X-04 tests

- `source_descriptor_redacts_userinfo_in_uri`
- `source_descriptor_rejects_oversized_uri`
- `source_descriptor_rejects_oversized_etag_or_version`
- `unsafe_reasons_include_untrusted_input`
- `unsafe_reasons_include_unsafe_extension`
- `unsafe_reasons_include_missing_provenance`

## A6X-04 Implementation Plan (Execution-Ready)

### Objective

Ship descriptor security and unsafe-cause explainability without breaking existing artifact compatibility:
- sanitize/redact source descriptors before persistence/hashing
- bound descriptor field sizes to prevent unbounded metadata growth
- emit explicit `unsafe_reasons[]` alongside `unsafe_surface`
- preserve default "metadata only" behavior (no raw-row payloads in artifacts)

### Sequencing

1. `swarm-torch-core/src/dataops.rs` (types + canonical helpers)
2. `swarm-torch/src/artifacts.rs` (writer/session enforcement)
3. `swarm-torch/src/report.rs` (reader tolerance + rendering compatibility check)
4. tests + conformance gates

### File-by-File Changes

#### 1) `swarm-torch-core/src/dataops.rs`

Add descriptor guardrails and unsafe taxonomy primitives first:

- Add `UnsafeReasonV0` enum:
  - `UntrustedInput`
  - `UnsafeExtension`
  - `MissingProvenance`
- Extend `MaterializationRecordV2`:
  - `#[serde(default, skip_serializing_if = "Vec::is_empty")]`
  - `pub unsafe_reasons: Vec<UnsafeReasonV0>`
- Add descriptor limits:
  - `MAX_SOURCE_URI_LEN`
  - `MAX_ETAG_OR_VERSION_LEN`
- Add descriptor error type:
  - `SourceDescriptorError::{UriTooLong, EtagOrVersionTooLong}`
- Add canonical sanitization helper (no new heavy deps):
  - `sanitize_source_descriptor_v0(&SourceDescriptorV0) -> Result<SourceDescriptorV0, SourceDescriptorError>`
  - redact URI userinfo (`scheme://user[:pass]@host/...` -> `scheme://<redacted>@host/...`)
  - trim-normalize preserved
  - reject over-limit `uri` and `etag_or_version`
- Keep `source_fingerprint_v0` deterministic by hashing sanitized/normalized descriptor form.

Invariants after this step:
- any persisted source descriptor is sanitized
- source fingerprint is stable for equivalent sanitized descriptors
- v2 materialization shape can carry explainable unsafe causes

#### 2) `swarm-torch/src/artifacts.rs`

Integrate guardrails into write path and emit reason taxonomy:

- In `DataOpsSession::register_source(...)`:
  - sanitize input descriptor before hashing/writing `DatasetEntryV1`
  - map `SourceDescriptorError` -> `io::ErrorKind::InvalidInput`
  - persist sanitized descriptor (never raw userinfo)
- In `DataOpsSession::materialize_node_outputs(...)`:
  - compute `unsafe_reasons` deterministically:
    - include `UnsafeReasonV0::UntrustedInput` when any input trust is untrusted
    - include `UnsafeReasonV0::UnsafeExtension` when `execution_trust != Core`
  - maintain `unsafe_surface == !unsafe_reasons.is_empty()`
  - emit reasons into `MaterializationRecordV2`
- Compatibility behavior:
  - fail-closed checks stay unchanged (missing inputs/invalid fingerprints still error)
  - no new raw-row or secret-bearing fields added to artifacts.

Invariants after this step:
- no source descriptor with embedded credentials is written
- unsafe decisions are explainable from artifact records, not only boolean flags
- existing fail-closed materialization guarantees are preserved

#### 3) `swarm-torch/src/report.rs`

Confirm report path remains stable with v2 reason field:

- Ensure `load_report()` continues to deserialize old and new `materializations.ndjson`
- Keep current unsafe derivation logic (`is_node_unsafe`) as source of truth for rendering
- Optional display follow-up (non-blocking for A6X-04): show `unsafe_reasons` when present in timeline details.

Invariants after this step:
- report generation remains backward-compatible with v1/v2 records
- no regression in current unsafe derivation behavior

### Test Mapping (Exact)

#### Descriptor security

- `source_descriptor_redacts_userinfo_in_uri`
  - file: `swarm-torch-core/src/dataops.rs` tests
  - asserts `sanitize_source_descriptor_v0` strips userinfo and keeps host/path
- `source_descriptor_rejects_oversized_uri`
  - file: `swarm-torch/src/artifacts.rs` tests
  - asserts `register_source` fails with invalid input when URI exceeds cap
- `source_descriptor_rejects_oversized_etag_or_version`
  - file: `swarm-torch/src/artifacts.rs` tests
  - asserts `register_source` fails when etag/version exceeds cap

#### Unsafe taxonomy

- `unsafe_reasons_include_untrusted_input`
  - file: `swarm-torch/src/artifacts.rs` tests
  - asserts emitted v2 record has `unsafe_surface=true` and includes `UntrustedInput`
- `unsafe_reasons_include_unsafe_extension`
  - file: `swarm-torch/src/artifacts.rs` tests
  - asserts emitted v2 record includes `UnsafeExtension` for non-core execution trust
- `unsafe_reasons_include_missing_provenance`
  - file: `swarm-torch-core/src/dataops.rs` tests
  - asserts compatibility normalization path can represent missing provenance explicitly for legacy rows lacking provenance detail

### Acceptance Criteria

1. Descriptor redaction/size checks enforced before fingerprinting and persistence.
2. `MaterializationRecordV2` carries machine-readable unsafe reasons.
3. `unsafe_surface` and `unsafe_reasons` remain logically consistent.
4. Report loading remains backward-compatible with old run bundles.
5. Artifact outputs continue to contain metadata only (no raw-row payload defaults).

### Conformance Command Set (A6X-04)

```bash
cargo fmt --all -- --check
cargo test -p swarm-torch-core dataops::tests::source_descriptor
cargo test -p swarm-torch unsafe_reasons
cargo test --workspace
cargo clippy --workspace --all-targets --all-features -- -D warnings
```

## Minimal `MaterializationRecordV2` Proposal

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum CacheDecisionV0 { Hit, Miss, Bypass, Unknown }

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum MaterializationStatusV0 { Ok, Error, Skipped }

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum UnsafeReasonV0 { UntrustedInput, UnsafeExtension, MissingProvenance, MissingInput }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualitySummaryV0 {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub null_rate: Option<f64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub row_count_delta: Option<i64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub schema_changed: Option<bool>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MaterializationRecordV2 {
    pub schema_version: u32, // = 2
    pub record_seq: u64,     // monotonic per run
    pub ts_unix_nanos: u64,

    pub asset_key: String,
    pub fingerprint_v0: String,
    pub node_id: NodeId,
    pub node_def_hash: String,
    pub op_type: String,

    pub input_asset_keys: Vec<String>,
    pub input_fingerprints_v0: Vec<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub rows: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub bytes: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub duration_ms: Option<u64>,

    pub cache_decision: CacheDecisionV0,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cache_reason: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cache_key_v0: Option<String>,

    // compatibility convenience field derived from cache_decision
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cache_hit: Option<bool>,

    pub unsafe_surface: bool,
    #[serde(default, skip_serializing_if = "Vec::is_empty")]
    pub unsafe_reasons: Vec<UnsafeReasonV0>,

    pub status: MaterializationStatusV0,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error_code: Option<String>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality: Option<QualitySummaryV0>,
}
```

## Migration Strategy

1. Keep path: `datasets/materializations.ndjson`.
2. Reader supports both versions via compatibility enum (`V1 | V2`) and normalizes in memory.
3. Writer emits v2 when A6X-02 lands.
4. No backfill required for old run bundles.

## ADR and PRD/WP Changes

### ADR-0017 amendment: "Emitter Correctness Invariants"

- `materialize_node_outputs` MUST fail on missing declared inputs.
- Input provenance MUST be snapshotted before registry mutation.
- Output contract MUST validate against `graph.json` (`node.outputs`).
- Materialization records MUST include input provenance fields.

### ADR-0016 amendment: "Durability/Throughput Profiles"

- Define strict vs streaming artifact modes.
- Define manifest policy modes: `final_only`, `interval_n`, `always`.
- Document expected consistency guarantees per mode.

### ADR-0018 amendment: "Unsafe Cause Taxonomy"

- Require explicit `unsafe_reasons[]` (not only boolean `unsafe_surface`).
- Require policy decision evidence for denied/bypassed nodes in emitted artifacts/events.

### PRD/WP acceptance criteria

- From artifacts only, reconstruct upstream path for any output.
- Detect schema drift and trust boundary crossings from run bundle alone.
- Enforce emission overhead budget (define p95 per materialization on coordinator profile).
- Prove zero raw-row leakage by default via conformance tests.

## Execution Order

1. A6X-01  
2. A6X-02  
3. A6X-04  
4. A6X-03  
5. A6X-05

## Conformance Command Set (baseline)

```bash
cargo fmt --all -- --check
cargo test --workspace
cargo build -p swarm-torch-core --no-default-features --features alloc
cargo run -p swarm-torch --example artifact_pipeline
```
