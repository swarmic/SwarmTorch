# SwarmTorch v0.1.0-alpha.6 Release Notes

**Date:** 2026-02-11  
**Type:** Contract Hardening + Cache-Hit Detection + OpRunner + Report Derivations  

## Summary

This release hardens the DataOps contract surface across five phases. Key themes: **fail-closed semantics** — every validation path rejects bad state explicitly; **deterministic prediction** — cache-hit detection uses pure fingerprint computation; **derived trust** — report unsafe status is derived from inputs and execution trust rather than relying on stored flags.

**Fixes in this release:**
- **Bidirectional output contract:** `materialize_node_outputs()` and `predict()` now reject both undeclared outputs AND missing declared outputs
- **Invalid fingerprint hex rejection:** Input fingerprints must be valid 64-char hex; malformed values are rejected at materialization/prediction time
- **Pre-mutation lineage correctness:** Lineage edges snapshot input fingerprints BEFORE output insertion, preventing corruption on in-place re-materialization

---

## Key Changes

### 1. Contract Hardening (Phase 1 + 3A)

**File:** `swarm-torch-core/src/dataops.rs`

**What:** Added canonical fingerprint helpers that all derivation paths must use:

```rust
pub fn derived_source_fingerprint_v0(asset_key: &str) -> [u8; 32];
pub fn no_schema_hash_v0() -> [u8; 32];
pub fn derived_dataset_entry_v1(asset_key, node, upstream_fingerprints, schema, trust) -> DatasetEntryV1;
```

**Why:** Eliminates ad-hoc SHA-256 string hashing scattered across modules. Every fingerprint derivation now goes through a single canonical path, preventing divergence between prediction and materialization.

**File:** `swarm-torch/src/artifacts.rs`

**What:** `materialize_node_outputs()` hardened with seven pre-validation checks:

| Check | Failure Mode | Error |
|-------|-------------|-------|
| Duplicate output `asset_key` | `InvalidInput` | `duplicate output asset_key: {key}` |
| Output not declared in `node.outputs[]` | `InvalidInput` | `output {key} not declared in node {node}` |
| Declared output missing from `outputs` | `InvalidInput` | `missing declared node output {key}` |
| Duplicate keys in `node.outputs[]` | `InvalidInput` | `duplicate node output asset_key {key}` |
| Input `asset_key` missing from registry | `InvalidInput` | `missing input asset: {key}` |
| Input fingerprint invalid hex | `InvalidData` | `invalid fingerprint for input {key}` |
| Input fingerprints snapshotted pre-mutation | N/A | Lineage edges reference pre-insert state |

**Design decision:** The bidirectional output contract ensures callers can never silently omit a declared output or add an undeclared one. This prevents partial materializations from corrupting the pipeline state.

**ADR Reference:** ADR-0017 (deterministic hashing), ADR-0016 (artifact spine)

### 2. E2E Integration Example (Phase 2)

**File:** `swarm-torch/examples/artifact_pipeline.rs` [NEW]

**What:** Full end-to-end example: source registration → 2 transforms → finalize → report generation.

**Assertions validated:**
- Manifest integrity (`validate_manifest()`)
- Unsafe surface detection (extension transform → `unsafe_surface = true`)
- Fingerprint uniqueness (all outputs distinct)
- Lineage edges are emitted and persisted in bundle artifacts

**Why:** Provides a runnable proof-of-correctness for the full artifact pipeline. Catches integration regressions that unit tests miss.

### 3. Cache-Hit Detection (Phase 3)

**File:** `swarm-torch-core/src/dataops.rs`

**What:** Pure, deterministic fingerprint prediction:

```rust
pub fn predict_output_fingerprints(
    node: &NodeV1,
    outputs: &[OutputSpecCore],
    upstream_fingerprints: &[[u8; 32]],
) -> Vec<PredictedOutput>;
```

**File:** `swarm-torch/src/artifacts.rs`

**What:** Session-level prediction and cache-hit API:

```rust
pub fn predict(&self, node, outputs) -> Result<Vec<PredictedOutput>, PredictError>;
pub fn is_cache_hit(&self, asset_key, predicted_fp) -> bool;
```

**Design decisions:**
- `predict()` is fail-closed: `PredictError::MissingInput` or `PredictError::InvalidFingerprint` on any bad state
- `predict()` enforces output-contract parity with materialization via `PredictError::OutputContract`
- `PredictError` includes `asset_key` for auditability (B5: no silent discard)
- Schema-aware: `OutputSpecCore` optionally accepts `SchemaDescriptorV0` for exact schema matching
- Asset-key scoped: `is_cache_hit()` checks one asset at a time to avoid all-or-nothing cache decisions

**ADR Reference:** ADR-0017 (canonical hashing), ADR-0018 (runner boundary)

### 4. Minimal OpRunner (Phase 4)

**File:** `swarm-torch/src/native_runner.rs` [NEW, std-gated]

**What:** `NativeOpRunner` implementing the `OpRunner` trait with three metadata-only operations:

| Op | Behavior |
|----|----------|
| `passthrough` | Forwards inputs unchanged |
| `filter_rows` | Forwards inputs (actual filtering deferred to real runner) |
| `union` | Forwards input metadata (output derivation occurs during materialization) |

**Deterministic spans:**
- `trace_id = run_id` (16 bytes → `TraceId`)
- `span_id = sha256(node_id_bytes \|\| ts_nanos_be)[0..8]`

**Design decisions:**
- `ExecutionContext { run_id, clock_nanos }` struct separates clock injection for deterministic testing
- `run_with_context()` is the primary entry point; `OpRunner::run()` falls back to system clock + zero-filled `RunId`
- Unsupported `op_type` returns `Err`, never silently drops (B5: no silent discard)
- Module gated behind `#[cfg(feature = "std")]` (B2: embedded profile compliance)

**ADR Reference:** ADR-0018 (OpRunner + ExecutionPolicy boundaries)

### 5. Report Derivations (Phase 5)

**File:** `swarm-torch/src/report.rs`

**What:** New `is_node_unsafe()` helper derives unsafe status from runtime data rather than relying on a stored boolean:

```rust
pub fn is_node_unsafe(node: &NodeV1, registry: &DatasetRegistryV1) -> bool;
```

A node is unsafe if:
- `execution_trust != Core`, OR
- any input `asset_key` is `TrustClass::Untrusted` in the registry, OR
- any input `asset_key` is **missing** from the registry (fail closed)

**Updated report rendering:**
- **SVG border:** Uses derived unsafe for red border + "UNSAFE" label
- **Warning banner:** Scans nodes with `is_node_unsafe()` instead of stored flag + trust check
- **Timeline detail:** Materialization rows now include `node_id` and `node_def_hash`

**Why:** The `unsafe_surface` stored flag can be stale or set by external tooling. Deriving from execution trust + actual input state is correct by construction.

### 6. Write-Profile + Delta Replay Follow-up

**Files:** `swarm-torch/src/artifacts.rs`, `swarm-torch/src/report.rs`

**What (artifacts):**
- Added write-profile controls:
  - `SnapshotProfile::{Strict, Streaming { snapshot_every_n_writes }}`
  - `ManifestRefreshPolicy::{FinalOnly, IntervalN, Always}`
  - `ArtifactWriteProfile` and `RunArtifactSink::with_profile(...)`
- Added append-only delta logs:
  - `datasets/registry_updates.ndjson`
  - `datasets/lineage_edges.ndjson`
- `DataOpsSession` now supports profile-aware snapshot compaction cadence while preserving fail-closed output contract checks.

**What (report):**
- `load_report()` now merges `registry.json`/`lineage.json` snapshots with optional delta logs for mid-run visibility.
- Added coverage test: `mid_run_report_succeeds_with_manifest_always_policy`.

**Why:**
- Reduces write amplification in streaming workflows.
- Keeps report rendering coherent for in-progress runs when manifest freshness is configured (`Always`/`IntervalN`).

---

## Post-Phase Audit Cleanup

A repo-wide edge-case and strict-lint sweep was completed after the phase work landed.

### Core correctness hardening

**Files:** `swarm-torch-core/src/aggregation.rs`, `swarm-torch-core/src/compression.rs`

- Aggregators now validate gradient shape invariants before computing results:
  - reject empty update sets
  - reject empty gradient vectors
  - reject mismatched gradient lengths
- Sparse decompression now ignores out-of-bounds indices instead of risking panic.
- `compression_ratio()` is now defined for empty inputs (`1.0`) to avoid undefined behavior.

### Canonical hashing panic removal

**Files:** `swarm-torch-core/src/run_graph.rs`, `swarm-torch-core/src/dataops.rs`

- Removed `expect(...)` from postcard hashing helpers.
- If canonical serialization fails, hashing now falls back to deterministic, namespaced sentinel digests (stable and fail-safe for runtime paths).

### Defaults and lint compliance cleanup

**Files:** `swarm-torch-core/src/run_graph.rs`, `swarm-torch-core/src/dataops.rs`, `swarm-torch-core/src/identity.rs`, `swarm-torch-core/src/compression.rs`, `swarm-torch-net/src/traits.rs`, `swarm-torch-runtime/src/lib.rs`, `swarm-torch/src/artifacts.rs`, `swarm-torch/src/report.rs`

- Replaced multiple manual `Default` impls with derive-based defaults where possible.
- Upgraded IO error mapping to `io::Error::other(...)` for consistency and clippy compliance.
- Removed `field_reassign_with_default` and `manual_contains` patterns flagged by strict lint.
- `report.rs` path serializer now takes `&Path` instead of `&PathBuf`.

### Cross-crate build integrity fixes

**Files:** `swarm-torch-models/Cargo.toml`, `swarm-torch-models/src/simple.rs`, `swarm-torch-net/src/protocol.rs`, `swarm-torch-net/src/lib.rs`

- Added missing `postcard` workspace dependency to `swarm-torch-models`.
- Removed unnecessary unit expression in `swarm-torch-models::SimpleModel::forward`.
- Gated `PeerId` import in `protocol.rs` under `alloc` to eliminate non-alloc warnings.
- Re-exported `MockNetwork` under `alloc` to prevent dead-code drift in strict all-features linting.

---

## Tests Added

| Test | Module | Invariant |
|------|--------|-----------|
| `materialize_fails_on_missing_input_asset` | artifacts | Missing input → `Err` (fail closed) |
| `materialize_fails_on_invalid_input_fingerprint_hex` | artifacts | Non-hex fingerprint → `Err` |
| `lineage_uses_pre_mutation_input_fingerprint_for_in_place_transform` | artifacts | In-place re-materialization uses pre-mutation fingerprint |
| `materialize_rejects_output_not_declared_in_node` | artifacts | Undeclared output → `Err` |
| `materialize_rejects_missing_declared_node_output` | artifacts | Missing declared output → `Err` |
| `materialize_rejects_duplicate_output_asset_keys` | artifacts | Duplicate output key → `Err` |
| `materialize_rejects_duplicate_declared_node_outputs` | artifacts | Duplicate keys in `node.outputs[]` → `Err` |
| `predict_err_on_missing_input` | artifacts | Prediction with missing input → `PredictError` |
| `predict_err_on_output_contract_violation` | artifacts | Prediction output list must match node output contract |
| `schema_aware_prediction_matches_materialization` | artifacts | Predicted fingerprint == materialized fingerprint |
| `cache_hit_is_asset_key_scoped` | artifacts | Cache check is per-asset, not global |
| `passthrough_preserves_inputs` | native_runner | Outputs == inputs; span emitted |
| `filter_rows_metadata_only` | native_runner | Metadata-only filter; span emitted |
| `union_metadata_only_forwards_inputs` | native_runner | Metadata-only union keeps runner behavior deterministic |
| `deterministic_span_id_is_stable` | native_runner | Same (node_id, ts) → same span_id; different → different |
| `unsupported_op_type_returns_error` | native_runner | Unknown op_type → `Err` (fail closed) |
| `report_marks_node_unsafe_on_untrusted_input` | report | Untrusted input → derived unsafe |
| `report_marks_node_unsafe_on_missing_input_registry_entry` | report | Missing input → derived unsafe (fail closed) |
| `report_node_safe_with_core_trust_and_trusted_inputs` | report | Core trust + trusted inputs → safe |
| `timeline_materialization_includes_node_id_and_node_def_hash` | report | Timeline detail contains node_id + node_def_hash |
| `fedavg_rejects_mismatched_gradient_dimensions` | core/aggregation | Reject gradient shape mismatches |
| `trimmed_mean_rejects_mismatched_gradient_dimensions` | core/aggregation | Reject gradient shape mismatches |
| `coordinate_median_rejects_empty_gradient_vectors` | core/aggregation | Reject empty gradient vectors |
| `decompress_sparse_ignores_out_of_bounds_indices` | core/compression | Ignore invalid sparse indices safely |
| `compression_ratio_is_well_defined_for_empty_input` | core/compression | Empty input ratio remains defined |

---

## Rule Compliance Audit

| Rule | Status | Evidence |
|------|--------|----------|
| No `unwrap`/`expect` in production | ✓ | Canonical postcard helpers no longer use `expect`; runtime paths return or recover deterministically |
| Fail closed (B5) | ✓ | `PredictError`, `io::Error` on every validation failure; unsupported ops return `Err` |
| Determinism (B3) | ✓ | No `HashMap` in canonical paths; `BTreeMap` for registry; stable iteration order for fingerprints |
| no\_std clean (B2) | ✓ | `native_runner.rs` gated behind `std`; `predict_output_fingerprints()` uses only `alloc` types |
| No silent discard (B5) | ✓ | All rejections return structured errors with asset key identification |
| Canonical hashing (B3) | ✓ | All fingerprints through `sha256_postcard` / `dataset_fingerprint_v0`; no ad-hoc hashing |
| `unsafe` policy (B6) | ✓ | No `unsafe` blocks in any changed files |
| Comments (no organizational summaries) | ✓ | Comments explain WHY (safety invariants, protocol rationale) |

---

## Documented Limitations

**OpRunner is metadata-only (alpha.6):**
```rust
/// The NativeOpRunner produces metadata-only results: filter_rows and union
/// do not actually transform row data. Real data transformation requires
/// integration with a compute engine (Arrow, Polars, etc.) in a future release.
```

**Cache-hit prediction requires registry population:**
```rust
/// predict() fails closed if any input asset_key is missing from the session
/// registry. Callers must register all inputs before predicting outputs.
```

**Policy-before-cache orchestration is caller-owned (alpha.6):**
```rust
/// ExecutionPolicy checks and cache decisions are validated in the integration
/// example flow, but no dedicated orchestrator API exists yet.
```

---

## Migration Notes

### API additions (no breaking changes)

| API | Location |
|-----|----------|
| `predict()` | `DataOpsSession` (artifacts.rs) |
| `is_cache_hit()` | `DataOpsSession` (artifacts.rs) |
| `is_node_unsafe()` | `report.rs` (public) |
| `NativeOpRunner` | `native_runner.rs` (std-only) |
| `ExecutionContext` | `native_runner.rs` (std-only) |
| `predict_output_fingerprints()` | `dataops.rs` (core, no\_std compatible) |
| `OutputSpecCore` | `dataops.rs` (core) |
| `PredictedOutput` | `dataops.rs` (core) |

### Behavioral changes

- `materialize_node_outputs()` now **rejects** calls where `outputs` does not exactly match `node.outputs[]` (bidirectional contract enforcement). Callers that previously materialized a subset of declared outputs must update to provide all declared outputs.
- Report SVG and warning banner now use **derived** unsafe status (from trust + inputs) instead of the stored `unsafe_surface` flag. Reports may show additional unsafe nodes if untrusted inputs were previously missed.
- Timeline materialization detail now includes `node_id` and `node_def_hash` fields.

---

## Verification

```bash
cargo fmt --all -- --check                                          # Clean
cargo test --workspace                                              # 31 pass (swarm-torch)
cargo build -p swarm-torch-core --no-default-features --features alloc  # no_std OK
cargo run -p swarm-torch --example artifact_pipeline                # All assertions pass
cargo clippy --workspace --all-targets --all-features -- -D warnings # Clean
```

---

## ADR References

- ADR-0016: Artifact spine schema (registry.json, lineage.json, materializations.ndjson)
- ADR-0017: Deterministic hashing (recipe_hash_v0, dataset_fingerprint_v0, canonical placeholders)
- ADR-0018: ExecutionPolicy + OpRunner boundaries

---

## Contributors

- Contract hardening and cache-hit detection: SwarmTorch team
- OpRunner implementation: SwarmTorch team
- Report derivations: SwarmTorch team
